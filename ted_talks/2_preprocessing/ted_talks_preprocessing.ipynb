{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "raw_data=pd.read_csv('https://github.com/aaas24/python_projects/raw/master/PUBLISHED/ted_talks/1_raw_data/final_raw_data.csv')\n",
    "df=raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         int64\n",
       "title             object\n",
       "author_x          object\n",
       "date              object\n",
       "views              int64\n",
       "likes              int64\n",
       "link              object\n",
       "url               object\n",
       "author_y          object\n",
       "title_1           object\n",
       "title_2           object\n",
       "description_1     object\n",
       "description2     float64\n",
       "duration_seg       int64\n",
       "release_date      object\n",
       "keywords          object\n",
       "description_2     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_x          0.018382\n",
       "description2    100.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing data\n",
    "((df\n",
    " .isna()\n",
    " .mean()\n",
    " *100)\n",
    " .pipe(lambda ser:ser[ser>0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "title               0\n",
       "author_x            1\n",
       "date                0\n",
       "views               0\n",
       "likes               0\n",
       "link                0\n",
       "url                 0\n",
       "author_y            0\n",
       "title_1             0\n",
       "title_2             0\n",
       "description_1       0\n",
       "description2     5440\n",
       "duration_seg        0\n",
       "release_date        0\n",
       "keywords            0\n",
       "description_2       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final cleaning columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with duplicated data or not useful\n",
    "drop_column=['description2', 'Unnamed: 0', 'link', 'author_y', 'title','url', 'title_1']\n",
    "df2=df.drop(drop_column,axis=1)\n",
    "df2.head(30)\n",
    "df_result=df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['author_x', 'date', 'views', 'likes', 'title_2', 'description_1',\n",
       "       'duration_seg', 'release_date', 'keywords', 'description_2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column names\n",
    "df_result.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['author', 'date_recorded', 'views', 'likes', 'title',\n",
       "       'description_1', 'duration_seg', 'date_released', 'keywords',\n",
       "       'description_2'], dtype=object)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=['author', 'date_recorded', 'views', 'likes', 'title',\n",
    "       'description_1', 'duration_seg', 'date_released', 'keywords','description_2']\n",
    "df_result.columns=column_names\n",
    "df_result.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description_1</th>\n",
       "      <th>description_2</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>date_released</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>duration_seg</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ozawa Bineshi Albert</td>\n",
       "      <td>Climate action needs new frontline leadership</td>\n",
       "      <td>\"We can't rely on those who created climate ch...</td>\n",
       "      <td>\"We can't rely on those who created climate ch...</td>\n",
       "      <td>December 2021</td>\n",
       "      <td>2022-02-18 09:41:43</td>\n",
       "      <td>404000</td>\n",
       "      <td>12000</td>\n",
       "      <td>834</td>\n",
       "      <td>['TED', ' talks', ' climate change', ' global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sydney Iaukea</td>\n",
       "      <td>The dark history of the overthrow of Hawaii</td>\n",
       "      <td>\"On January 16th, 1895, two men arrived at Lil...</td>\n",
       "      <td>\"On January 16th, 1895, two men arrived at Lil...</td>\n",
       "      <td>February 2022</td>\n",
       "      <td>2022-02-17 10:13:22</td>\n",
       "      <td>214000</td>\n",
       "      <td>6400</td>\n",
       "      <td>0</td>\n",
       "      <td>['TED', ' talks', ' education', ' women', ' TE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin Reeves</td>\n",
       "      <td>Why play is essential for business</td>\n",
       "      <td>\"To thrive in today's competitive economy, you...</td>\n",
       "      <td>\"To thrive in today's competitive economy, you...</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>2022-02-17 09:51:37</td>\n",
       "      <td>412000</td>\n",
       "      <td>12000</td>\n",
       "      <td>665</td>\n",
       "      <td>['TED', ' talks', ' business', ' leadership', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James K. Thornton</td>\n",
       "      <td>Why is China appointing judges to combat clima...</td>\n",
       "      <td>\"Why is China appointing thousands of judges t...</td>\n",
       "      <td>\"Why is China appointing thousands of judges t...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>2022-02-16 09:45:34</td>\n",
       "      <td>427000</td>\n",
       "      <td>12000</td>\n",
       "      <td>695</td>\n",
       "      <td>['TED', ' talks', ' climate change', ' polluti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mahendra Singhi</td>\n",
       "      <td>Cement's carbon problem -- and 2 ways to fix it</td>\n",
       "      <td>\"Cement is vital to modernizing all kinds of i...</td>\n",
       "      <td>\"Cement is vital to modernizing all kinds of i...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>2022-02-16 09:38:48</td>\n",
       "      <td>2400</td>\n",
       "      <td>72</td>\n",
       "      <td>671</td>\n",
       "      <td>['TED', ' talks', ' climate change', ' Countdo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                              title  \\\n",
       "0  Ozawa Bineshi Albert      Climate action needs new frontline leadership   \n",
       "1         Sydney Iaukea        The dark history of the overthrow of Hawaii   \n",
       "2         Martin Reeves                 Why play is essential for business   \n",
       "3     James K. Thornton  Why is China appointing judges to combat clima...   \n",
       "4       Mahendra Singhi    Cement's carbon problem -- and 2 ways to fix it   \n",
       "\n",
       "                                       description_1  \\\n",
       "0  \"We can't rely on those who created climate ch...   \n",
       "1  \"On January 16th, 1895, two men arrived at Lil...   \n",
       "2  \"To thrive in today's competitive economy, you...   \n",
       "3  \"Why is China appointing thousands of judges t...   \n",
       "4  \"Cement is vital to modernizing all kinds of i...   \n",
       "\n",
       "                                       description_2   date_recorded  \\\n",
       "0  \"We can't rely on those who created climate ch...   December 2021   \n",
       "1  \"On January 16th, 1895, two men arrived at Lil...   February 2022   \n",
       "2  \"To thrive in today's competitive economy, you...  September 2021   \n",
       "3  \"Why is China appointing thousands of judges t...    October 2021   \n",
       "4  \"Cement is vital to modernizing all kinds of i...    October 2021   \n",
       "\n",
       "         date_released   views  likes  duration_seg  \\\n",
       "0  2022-02-18 09:41:43  404000  12000           834   \n",
       "1  2022-02-17 10:13:22  214000   6400             0   \n",
       "2  2022-02-17 09:51:37  412000  12000           665   \n",
       "3  2022-02-16 09:45:34  427000  12000           695   \n",
       "4  2022-02-16 09:38:48    2400     72           671   \n",
       "\n",
       "                                            keywords  \n",
       "0  ['TED', ' talks', ' climate change', ' global ...  \n",
       "1  ['TED', ' talks', ' education', ' women', ' TE...  \n",
       "2  ['TED', ' talks', ' business', ' leadership', ...  \n",
       "3  ['TED', ' talks', ' climate change', ' polluti...  \n",
       "4  ['TED', ' talks', ' climate change', ' Countdo...  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colum_names_reordered=['author', 'title','description_1','description_2','date_recorded', 'date_released','views', 'likes', \n",
    "        'duration_seg',  'keywords']\n",
    "df_end=df_result[colum_names_reordered]\n",
    "df_end.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_end.copy()\n",
    "type(df['date_recorded'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  date_recorded  date_recorded_year  date_recorded_month\n",
      "0    2021-12-01                2021                   12\n",
      "1    2022-02-01                2022                    2\n",
      "2    2021-09-01                2021                    9\n",
      "3    2021-10-01                2021                   10\n",
      "4    2021-10-01                2021                   10\n",
      "5    2021-10-01                2021                   10\n",
      "6    2022-02-01                2022                    2\n",
      "7    2021-08-01                2021                    8\n",
      "8    2022-02-01                2022                    2\n",
      "9    2019-03-01                2019                    3\n"
     ]
    }
   ],
   "source": [
    "#modifying the date_recorded variable\n",
    "df_ini=df_end.copy()\n",
    "df=pd.DataFrame()\n",
    "df['date_recorded']=df_ini['date_recorded']\n",
    "df['date_recorded']= pd.to_datetime(df['date_recorded'], format='%B %Y')\n",
    "# # Add Column with months\n",
    "list_months=[]\n",
    "list_years=[]\n",
    "for i in range(df.shape[0]):\n",
    "    list_months.append(df['date_recorded'][i].month)\n",
    "    list_years.append(df['date_recorded'][i].year)\n",
    "df['date_recorded_year']=list_years\n",
    "df['date_recorded_month']=list_months\n",
    "print(df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date_released  date_released_year  date_released_month  \\\n",
      "0 2022-02-18 09:41:43                2022                    2   \n",
      "1 2022-02-17 10:13:22                2022                    2   \n",
      "2 2022-02-17 09:51:37                2022                    2   \n",
      "3 2022-02-16 09:45:34                2022                    2   \n",
      "4 2022-02-16 09:38:48                2022                    2   \n",
      "5 2022-02-15 09:29:19                2022                    2   \n",
      "6 2022-02-14 10:01:51                2022                    2   \n",
      "7 2022-02-14 09:57:02                2022                    2   \n",
      "8 2022-02-14 09:53:24                2022                    2   \n",
      "9 2022-02-07 10:05:47                2022                    2   \n",
      "\n",
      "   date_released_hour  date_released_minute  \n",
      "0                   9                    41  \n",
      "1                  10                    13  \n",
      "2                   9                    51  \n",
      "3                   9                    45  \n",
      "4                   9                    38  \n",
      "5                   9                    29  \n",
      "6                  10                     1  \n",
      "7                   9                    57  \n",
      "8                   9                    53  \n",
      "9                  10                     5  \n"
     ]
    }
   ],
   "source": [
    "#modifying the date_released variable\n",
    "df_ini=df_end.copy()\n",
    "column='date_released'\n",
    "df=pd.DataFrame()\n",
    "df[column]=df_ini[column]\n",
    "df[column]= pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# # Add Column with months\n",
    "list_months=[]\n",
    "list_years=[]\n",
    "list_hours=[]\n",
    "list_minutes=[]\n",
    "for i in range(df.shape[0]):\n",
    "    list_months.append(df[column][i].month)\n",
    "    list_years.append(df[column][i].year)\n",
    "    list_hours.append(df[column][i].hour)\n",
    "    list_minutes.append(df[column][i].minute)\n",
    "df[column+'_year']=list_years\n",
    "df[column+'_month']=list_months\n",
    "df[column+'_hour']=list_hours\n",
    "df[column+'_minute']=list_minutes\n",
    "\n",
    "print(df.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords: \n",
    "#### What type of content is published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-478-d8a70b089cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"keywords\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "df=df_end.loc[0:100,\"keywords\"]\n",
    "df=str(','.join(df)).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "df2=pd.DataFrame(df)\n",
    "df2.str.get_dummies(',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ' Middle East'   ' activism'   ' community'   ' education'   ' equality'  \\\n",
      "0                1             1              1              1             1   \n",
      "\n",
      "    ' kids'   ' social change'   ' talks'   ' teaching'   ' women'  'TED'  \n",
      "0         1                  1          1             1          1      1  \n"
     ]
    }
   ],
   "source": [
    "def separate_list(df):\n",
    "    return ','.join(df)\n",
    "lines=[]\n",
    "df=df_end.loc[0:100,\"keywords\"]\n",
    "for i in range(0, df.shape[0]):\n",
    "    line=(\n",
    "        str(df_x[i])\n",
    "        .replace(\"[\",\"\")\n",
    "        .replace(\"]\",\"\")\n",
    "    )\n",
    "#     lines.append(line)\n",
    "#     df2[\"keywords2\"]=lines\n",
    "df2 = pd.DataFrame([line], columns=['keyword2'])\n",
    "df2=df2[\"keyword2\"].str.get_dummies(',')\n",
    "print(df2)\n",
    "\n",
    "\n",
    "\n",
    "# df_result=\n",
    "# (df['keywords']\n",
    "#  .apply(separate_list(df['keywords']))\n",
    "# )\n",
    "# print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TED' is in 10 lists\n",
      "'  talks' is in 10 lists\n",
      "'  atheism' is in 5 lists\n",
      "'  religion' is in 5 lists\n",
      "'  culture' is in 5 lists\n",
      "'  humor' is in 3 lists\n",
      "'  Christianity' is in 3 lists\n",
      "'  storytelling' is in 3 lists\n",
      "'  performance' is in 3 lists\n",
      "'  comedy' is in 3 lists\n",
      "'  environment' is in 3 lists\n",
      "'  sustainability' is in 3 lists\n",
      "'  technology' is in 2 lists\n",
      "'  global issues' is in 2 lists\n",
      "'  science' is in 2 lists\n",
      "'  evolution' is in 2 lists\n",
      "'  cognitive science' is in 2 lists\n",
      "'  philosophy' is in 2 lists\n",
      "'  consciousness' is in 2 lists\n",
      "'  brain' is in 2 lists\n",
      "'  business' is in 2 lists\n",
      "'  politics' is in 2 lists\n",
      "'  equality' is in 2 lists\n",
      "'  pollution' is in 2 lists\n",
      "'  cities' is in 2 lists\n",
      "'  activism' is in 2 lists\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "lists = []\n",
    "\n",
    "for i in range(5430, df.shape[0]):\n",
    "    line=(df_x[i]\n",
    "          .replace(\"[\",\"\")\n",
    "          .replace(\"]\",\"\")\n",
    "          .replace(\"'\",\"\")\n",
    "          .split(\",\")\n",
    "         )\n",
    "    lists.append(line)\n",
    "no_of_lists_per_name = Counter(chain.from_iterable(map(set, lists)))\n",
    "\n",
    "for name, no_of_lists in no_of_lists_per_name.most_common():\n",
    "    if no_of_lists == 1:\n",
    "        break # since it is ordered by count, once we get this low we are done\n",
    "    print(f\"'{name}' is in {no_of_lists} lists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education 10\n",
      "creativity 10\n",
      "evolution 10\n",
      "parenting 10\n",
      "TED Prize 10\n",
      "pollution 10\n",
      "cognitive science 10\n",
      "atheism 10\n",
      "transportation 10\n",
      "renewable energy 10\n",
      "religion 10\n",
      "science 10\n",
      "humor 10\n",
      "politics 10\n",
      "TED 10\n",
      "cities 10\n",
      "climate change 10\n",
      "equality 10\n",
      "ebola 10\n",
      "dance 10\n",
      "collaboration 10\n",
      "performance 10\n",
      "environment 10\n",
      "storytelling 10\n",
      "disease 10\n",
      "consciousness 10\n",
      "technology 10\n",
      "brain 10\n",
      "Christianity 10\n",
      "sustainability 10\n",
      "philosophy 10\n",
      "culture 10\n",
      "health 10\n",
      "talks 10\n",
      "activism 10\n",
      "teaching 10\n",
      "comedy 10\n",
      "kids 10\n",
      "global issues 10\n",
      "business 10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "lists = []\n",
    "list_fix=[]\n",
    "for i in range(5430, df.shape[0]):\n",
    "    line=(df_x[i]\n",
    "          .replace(\"[\",\"\")\n",
    "          .replace(\"]\",\"\")\n",
    "          .replace(\"'\",\"\")\n",
    "          .replace('\\t', '')\n",
    "          .split(\",\")\n",
    "         )\n",
    "    #recompose the line without spaces\n",
    "    for word in line:\n",
    "        list_fix.append(word.replace(' ', '',2))\n",
    "    lists.append(list_fix)\n",
    "no_of_lists_per_name = Counter(chain.from_iterable(map(set, lists)))\n",
    "\n",
    "for name, no_of_lists in no_of_lists_per_name.most_common():\n",
    "#     if no_of_lists == 1:\n",
    "#         break # since it is ordered by count, once we get this low we are done\n",
    "    print(name ,no_of_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TED\n",
      "talks\n",
      "TEDPrize\n",
      "collaboration\n",
      "disease\n",
      "ebola\n",
      "globalissues\n",
      "health\n",
      "science\n",
      "technology\n",
      "TED\n",
      "talks\n",
      "atheism\n",
      "brain\n",
      "cognitivescience\n",
      "consciousness\n",
      "evolution\n",
      "philosophy\n",
      "religion\n",
      "TED\n",
      "talks\n",
      "atheism\n",
      "brain\n",
      "cognitivescience\n",
      "consciousness\n",
      "evolution\n",
      "philosophy\n",
      "religion\n",
      "TED\n",
      "talks\n",
      "Christianity\n",
      "atheism\n",
      "comedy\n",
      "culture\n",
      "performance\n",
      "religion\n",
      "storytelling\n",
      "humor\n",
      "TED\n",
      "talks\n",
      "Christianity\n",
      "atheism\n",
      "comedy\n",
      "culture\n",
      "performance\n",
      "religion\n",
      "storytelling\n",
      "humor\n",
      "TED\n",
      "talks\n",
      "Christianity\n",
      "atheism\n",
      "comedy\n",
      "culture\n",
      "performance\n",
      "religion\n",
      "storytelling\n",
      "humor\n",
      "TED\n",
      "talks\n",
      "creativity\n",
      "culture\n",
      "dance\n",
      "education\n",
      "parenting\n",
      "teaching\n",
      "kids\n",
      "TED\n",
      "talks\n",
      "activism\n",
      "business\n",
      "cities\n",
      "environment\n",
      "politics\n",
      "pollution\n",
      "sustainability\n",
      "equality\n",
      "TED\n",
      "talks\n",
      "activism\n",
      "business\n",
      "cities\n",
      "environment\n",
      "politics\n",
      "pollution\n",
      "sustainability\n",
      "equality\n",
      "TED\n",
      "talks\n",
      "climatechange\n",
      "culture\n",
      "environment\n",
      "globalissues\n",
      "science\n",
      "sustainability\n",
      "technology\n",
      "transportation\n",
      "renewableenergy\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "for i in range(5430, df.shape[0]):\n",
    "    line=(df_x[i]\n",
    "          .replace(\"[\",\"\")\n",
    "          .replace(\"]\",\"\")\n",
    "          .replace(\"'\",\"\") \n",
    "          .split(\",\")\n",
    "         )\n",
    "    for word in line:\n",
    "            print(word.replace(' ', ''))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# df_x=df['keywords'].head(10)\n",
    "# cnt = Counter()\n",
    "# for i in range(0, df_x.shape[0]):\n",
    "#     words=(df_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# df_x=df['keywords']\n",
    "# #cnt = Counter()\n",
    "# list_words=[]\n",
    "# for i in range(0, df_x.shape[0]):\n",
    "#     words=df_x[i][1:-1]\n",
    "#     list_words.append(words)\n",
    "# #print(str(list_words).replace('\"',''))\n",
    "#     words=str(list_words).replace('\"','')\n",
    "#     cnt[words] += 1\n",
    "# cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize here the df to utilize. From here on, we will call this df\n",
    "df=df_result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what constitude a good video based on likes?\n",
    "y=1000\n",
    "df_graph=df.likes.apply(lambda x: round(x/y,0))\n",
    "df_graph.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what constitude a good video based on views?\n",
    "y=1000\n",
    "df_graph=df.views.apply(lambda x: round(x/y,0))\n",
    "df_graph.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Liked Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-480-88edbabddf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'likes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df_grap = (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'author_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'views'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     ).reset_index()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "#build data: These are the 75% most liked videos\n",
    "y_var='likes'\n",
    "df_grap = (\n",
    "    (df.groupby(['title','author_x','views', 'keywords'])[y_var].sum().reset_index())\n",
    "    .sort_values([y_var],ascending=[False])\n",
    "    ).reset_index()\n",
    "df_grap=df_grap.drop('index', axis=1)\n",
    "df_grap = df_grap[df_grap[y_var] > 65000]\n",
    "df_grap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is taking the 75% percentile on liked videos\n",
    "#Modifiable variables\n",
    "y_var='likes'\n",
    "\n",
    "#build data\n",
    "df_grap = (\n",
    "    (df.groupby(['title_2','author','views'])[y_var].sum().reset_index())\n",
    "    .sort_values([y_var],ascending=[False])\n",
    "    ).reset_index()\n",
    "df_grap=df_grap.drop('index', axis=1)\n",
    "df_grap = df_grap[df_grap[y_var] > 65000]\n",
    "df_grap.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifiable variables\n",
    "y_var='views'\n",
    "x_var1='author'\n",
    "x_var2='likes'\n",
    "\n",
    "#build data\n",
    "df_grap = (\n",
    "    (df.groupby([x_var1, x_var2])[y_var].sum().reset_index())\n",
    "    .sort_values([y_var],ascending=[False])\n",
    "    ).reset_index().head(10)\n",
    "df_grap=df_grap.drop('index', axis=1)\n",
    "df_grap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "x_var='author'\n",
    "y_var='views'\n",
    "sns.set_theme(style=\"white\")\n",
    "ax = sns.barplot(x=y_var, y=x_var, data=df_grap, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize\n",
    "x_var='author'\n",
    "y_var='likes'\n",
    "sns.set_theme(style=\"white\")\n",
    "ax = sns.barplot(x=y_var, y=x_var, data=df_grap, orient=\"h\", palette=\"Blues_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "`title`\n",
    "FROM\n",
    "df\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "print(sqldf(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Areas of improvements:\n",
    "    \n",
    "    1) More information on the authors. Understanding age, gender and nationality of authors, may answer questions related to diversity of the speakers. This data could be parcially scrapped from Wikipedia as there is a dedicated website that tracks this information. \n",
    "    https://en.wikipedia.org/wiki/List_of_TED_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
